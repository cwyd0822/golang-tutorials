## 已部分实现的目标
1. 模拟环境搭建(100%)
	- [http://10.6.0.11/](http://10.6.0.11/)
	- 表格
	- 图表
2. 表格内文本目标检测
	- 传统图像处理法，检出率90%
	- CNN的TextBoxes++和旷世EAST算法，检出率50%

3. 表格内文本识别
	- Tesseract识别法（识别正确率50%）

4. 视频采集卡，已验证可行(100%)
5. 飞易来硬件设备：鼠标可以控制（100%），键盘输入较慢（100%）
6. 树莓派蓝牙KM模拟，鼠标可以控制（100%），键盘在Linux下可以控制（100%），在Windows下无法控制键盘(0%，待研究突破)
7. 双公口USB线无法模拟KM，因为操作系统有安全限制(100%)
8. 将文件通过js转成二维码（100%）；通过抓拍页面上的二维码图片，利用图像处理和二维码识别技术对图像进行切割，获取二维码内容（100%）；当获取到二维码内容转成二进制数据，反序列化为文件（100%）；全流程自动化（0%）

## 难点与问题
1. 实现较为通用并且检出率高的结构化页面上的目标检测
2. OCR识别算法识别正确率低，需要改进
3. 树莓派的蓝牙与目标系统的蓝牙相连接，达到可以控制键盘的目的。需要研究Windows下怎样实现键盘模拟

## 接下来的目标：
1. 研究和改进CNN算法，在TextBoxex++的模型基础上，修改神经网络架构，实现工程上可行的结构化目标检测。可能会结合传统图像处理法，将两者结合，以提高目标检出率。
2. 利用CNN算法，研究deep-ocr模型或者tesseract的cnn模型，通过大量的中文字符训练网络，以期提高OCR识别正确率
3. 研究树莓派蓝牙在Windows操作系统下实现键盘模拟
